import json
import tensorflow as tf
import numpy as np

if tf.test.is_gpu_available():
    rnn = tf.keras.layers.CuDNNGRU
else:
    import functools
    rnn = functools.partial(tf.keras.layers.GRU, recurrent_activation='sigmoid', reset_after=True)


RNN_UNITS = 1024
EMBEDDING_DIM = 265

MAX_PREDICTION = 1000  # Maximum characters generated by the model
SENTENCE_SEPARATORS = '\n.'


def build_model(vocab_size, batch_size):
    model = tf.keras.Sequential([
        tf.keras.layers.Embedding(vocab_size, EMBEDDING_DIM, batch_input_shape=[batch_size, None]),
        rnn(RNN_UNITS,
            return_sequences=True,
            recurrent_initializer='glorot_uniform',
            stateful=True
        ),
        tf.keras.layers.Dense(vocab_size)
    ])
    return model


def load_encoding(enc_file):
    with open(enc_file) as file:
        char2idx = json.load(file)
    return char2idx


class Model:
    def __init__(self, encoding_file, weights_file):
        self.char2idx = load_encoding(encoding_file)
        self.vocab = sorted(list(self.char2idx.keys()))
        self.idx2char = np.array(self.vocab)
        self.weights_file = weights_file

    def generate_text(self, starting_string, num_sentences):
        task_model = self.__load_model__()
        return self.__generate_text__(task_model, starting_string, num_sentences)

    def __generate_text__(self, model, start_string, num_sentences):
        input_eval = [self.char2idx[s] for s in start_string]
        input_eval = tf.expand_dims(input_eval, 0)
        text_generated = []

        temperature = 1.0

        sentences_generated = 0

        for _ in range(MAX_PREDICTION):
            if sentences_generated >= num_sentences:
                break

            predictions = model(input_eval)
            predictions = tf.squeeze(predictions, 0)
            predictions = predictions / temperature
            predicted_id = tf.multinomial(predictions, num_samples=1)[-1, 0].numpy()
            input_eval = tf.expand_dims([predicted_id], 0)
            crt_char = self.idx2char[predicted_id]
            text_generated.append(crt_char)

            if crt_char in SENTENCE_SEPARATORS:
                sentences_generated = sentences_generated + 1

        return ''.join(text_generated)

    def __load_model__(self):
        model = build_model(
            len(self.vocab),
            batch_size=1
        )
        model.load_weights(self.weights_file)
        model.build(tf.TensorShape([1, None]))
        return model
